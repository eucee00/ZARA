# hello_world/ZB/zdl.py
# This is Zira's Deep Learning (DL) handler, supporting custom DL models and dynamic API fallbacks.

import json
import openai
import torch
import torch.nn as nn
import torch.optim as optim
from transformers import pipeline
from utils.logger import Logger


class ZDL:
    def __init__(self, path="hello_world/config.json", log_file_path='logs/zdl.log'):
        """
        Initializes the ZDL instance, loads the API key, and sets up logging for deep learning tasks.
        
        :param path: Path to the configuration file containing the OpenAI API key.
        :param log_file_path: Path to the log file for logging DL operations.
        """
        self.config = self.load_config(path)
        self.logger = Logger(log_file_path=log_file_path)
        
        # OpenAI API setup
        self.openai_api_key = self.config.get("openai_api_key")
        if self.openai_api_key:
            openai.api_key = self.openai_api_key
            self.logger.info("OpenAI API initialized.")
        else:
            self.logger.error("OpenAI API key is missing.")

        # Hugging Face pipeline for fallback
        self.hugging_face_generator = pipeline("automatic-speech-recognition", model="openai/whisper-large")

        self.logger.info("Zira Deep Learning initialized with available APIs.")

    def load_config(self, config_path):
        """
        Loads the configuration file and returns the API keys and other settings.
        
        :param config_path: Path to the configuration file containing the API key.
        :return: The API key as a string.
        :raises: FileNotFoundError, JSONDecodeError, ValueError for any loading errors.
        """
        try:
            with open(config_path, "r") as file:
                config = json.load(file)
                return config
        except FileNotFoundError:
            self.logger.error("Configuration file not found.")
            raise
        except (json.JSONDecodeError, ValueError) as e:
            self.logger.error(f"Error loading configuration: {e}")
            raise

    def perform_dl_task_openai(self, task_description, model="text-davinci-003", max_tokens=200, temperature=0.7):
        """
        Executes a deep learning task using OpenAI's models, based on a given task description.
        
        :param task_description: Description of the deep learning task to be performed.
        :param model: The OpenAI model to use for task execution (default: 'text-davinci-003').
        :param max_tokens: The maximum number of tokens in the response (default: 200).
        :param temperature: Controls the randomness of the response (default: 0.7).
        :return: The response generated by the model as a string.
        """
        try:
            prompt = f"Perform the following deep learning task: {task_description}"
            response = openai.Completion.create(
                engine=model,
                prompt=prompt,
                max_tokens=max_tokens,
                temperature=temperature
            )
            result = response.choices[0].text.strip()
            self.logger.info(f"Performed DL task with OpenAI: {task_description}")
            return result
        except openai.error.OpenAIError as e:
            self.logger.error(f"OpenAI error: {e}. Falling back to Hugging Face...")
            return self.perform_dl_task_huggingface(task_description)

    def perform_dl_task_huggingface(self, task_description):
        """
        Fallback to Hugging Face's text generation pipeline for deep learning tasks.
        
        :param task_description: Description of the task for Hugging Face to handle.
        :return: Generated text using Hugging Face's pipeline.
        """
        try:
            response = self.hugging_face_generator(task_description, max_length=200)
            result = response[0]['generated_text'].strip()
            self.logger.info(f"Performed DL task with Hugging Face for: {task_description}")
            return result
        except Exception as e:
            self.logger.error(f"Hugging Face error: {e}")
            return "Error: Failed to perform deep learning task"

    def train_custom_dl_model(self, X, y, input_dim, output_dim, epochs=10):
        """
        Trains a simple custom deep learning model using PyTorch (e.g., a fully connected neural network).
        
        :param X: Training input data.
        :param y: Training output labels.
        :param input_dim: Number of input features.
        :param output_dim: Number of output features (classes).
        :param epochs: Number of training epochs.
        :return: Trained PyTorch model.
        """
        try:
            model = SimpleNN(input_dim, output_dim)
            criterion = nn.CrossEntropyLoss()
            optimizer = optim.Adam(model.parameters(), lr=0.001)

            X = torch.tensor(X, dtype=torch.float32)
            y = torch.tensor(y, dtype=torch.long)

            for epoch in range(epochs):
                optimizer.zero_grad()
                outputs = model(X)
                loss = criterion(outputs, y)
                loss.backward()
                optimizer.step()

                if epoch % 2 == 0:
                    self.logger.info(f'Epoch [{epoch}/{epochs}], Loss: {loss.item():.4f}')
            self.logger.info("Custom deep learning model trained.")
            return model
        except Exception as e:
            self.logger.error(f"Error training custom DL model: {e}")
            raise


class SimpleNN(nn.Module):
    """
    A simple fully connected neural network for deep learning tasks.
    """
    def __init__(self, input_dim, output_dim):
        super(SimpleNN, self).__init__()
        self.fc1 = nn.Linear(input_dim, 128)
        self.fc2 = nn.Linear(128, 64)
        self.fc3 = nn.Linear(64, output_dim)

    def forward(self, x):
        x = torch.relu(self.fc1(x))
        x = torch.relu(self.fc2(x))
        x = self.fc3(x)
        return x
